{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP工具分词性能评测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "分词是几乎所有NLP任务的基石，这里我们会对主流的NLP工具：jieba, pkuseg, thulac, hannlp， snownlp, stanfordnlp（斯坦福） 进行分词性能评测， 评测的维度包括：\n",
    "- 速度\n",
    "- 精度"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "另外， 这个评测程序是可扩展的（评测程序详见[这里](https://github.com/superjcd/NLP_Application/tree/master/evaluation/word_segment\n",
    ")），可以应用在其他分词工具和测试文本上，扩展方法详见文末。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 准备工作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在开始正式评测之前， 我们需要准备好测试数据，包括两部分：\n",
    "- 原始语料\n",
    "- 正确分词的结果（一般为人工标注）  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面是我们的原始语料（前10条）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "“人们常说生活是一部教科书，而血与火的战争更是不可多得的教科书，她确实是名副其实的‘我的大学’。\n",
      "\n",
      "“心静渐知春似海，花深每觉影生香。\n",
      "\n",
      "“吃屎的东西，连一捆麦也铡不动呀？\n",
      "\n",
      "他“严格要求自己，从一个科举出身的进士成为一个伟大的民主主义者，进而成为一位杰出的党外共产主义战士，献身于崇高的共产主义事业。\n",
      "\n",
      "“征而未用的耕地和有收益的土地，不准荒芜。\n",
      "\n",
      "“这首先是个民族问题，民族的感情问题。\n",
      "\n",
      "’我扔了两颗手榴弹，他一下子出溜下去。\n",
      "\n",
      "“废除先前存在的所有制关系，并不是共产主义所独具的特征。\n",
      "\n",
      "“这个案子从始至今我们都没有跟法官接触过，也没有跟原告、被告接触过。\n",
      "\n",
      "“你只有把事情做好，大伙才服你。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_file ='/Users/jiangchaodi/PycharmProjects/NLPRoadMap/evaluation/word_segment/data/msr_raw.txt'\n",
    "n=1\n",
    "file = open(raw_file, 'r')\n",
    "for text in file:\n",
    "    if n<=10:\n",
    "        print(text)\n",
    "        n +=1\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面是人工分割后的数据："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "“ 人们 常 说 生活 是 一 部 教科书 ， 而 血 与 火 的 战争 更 是 不可多得 的 教科书 ， 她 确实 是 名副其实 的 ‘ 我 的 大学 ’ 。\n",
      "\n",
      "“ 心 静 渐 知 春 似 海 ， 花 深 每 觉 影 生 香 。\n",
      "\n",
      "“ 吃 屎 的 东西 ， 连 一 捆 麦 也 铡 不 动 呀 ？\n",
      "\n",
      "他 “ 严格要求 自己 ， 从 一个 科举 出身 的 进士 成为 一个 伟大 的 民主主义 者 ， 进而 成为 一 位 杰出 的 党外 共产主义 战士 ， 献身 于 崇高 的 共产主义 事业 。\n",
      "\n",
      "“ 征 而 未 用 的 耕地 和 有 收益 的 土地 ， 不准 荒芜 。\n",
      "\n",
      "“ 这 首先 是 个 民族 问题 ， 民族 的 感情 问题 。\n",
      "\n",
      "’ 我 扔 了 两颗 手榴弹 ， 他 一下子 出 溜 下去 。\n",
      "\n",
      "“ 废除 先前 存在 的 所有制 关系 ， 并不是 共产主义 所 独具 的 特征 。\n",
      "\n",
      "“ 这个 案子 从 始 至今 我们 都 没有 跟 法官 接触 过 ， 也 没有 跟 原告 、 被告 接触 过 。\n",
      "\n",
      "“ 你 只有 把 事情 做好 ， 大伙 才 服 你 。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "seg_file ='/Users/jiangchaodi/PycharmProjects/NLPRoadMap/evaluation/word_segment/data/msr_segmented.txt'\n",
    "n=1\n",
    "file = open(seg_file, 'r')\n",
    "for text in file:\n",
    "    if n<=10:\n",
    "        print(text)\n",
    "        n +=1\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 速度评测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "进入evaluation/word_segment/目录， 在shell端运行以下代码(raw参数是具体需要分词的原始文本所在位置, n为需要测试的行数)："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "python evaluate.py eval_time --raw=data/msr_raw.txt --n=10000\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "运行成功后， 会在result/time/下面的出现评测结果csv文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>分词工具</th>\n",
       "      <th>数据集</th>\n",
       "      <th>语句数量</th>\n",
       "      <th>运行时间</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jieba</td>\n",
       "      <td>MSR</td>\n",
       "      <td>10000</td>\n",
       "      <td>2.925063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hannlp</td>\n",
       "      <td>MSR</td>\n",
       "      <td>10000</td>\n",
       "      <td>12.746340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pkuseg</td>\n",
       "      <td>MSR</td>\n",
       "      <td>10000</td>\n",
       "      <td>14.527033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thulac</td>\n",
       "      <td>MSR</td>\n",
       "      <td>10000</td>\n",
       "      <td>15.325316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>snownlp</td>\n",
       "      <td>MSR</td>\n",
       "      <td>10000</td>\n",
       "      <td>122.612315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>stanfordnlp</td>\n",
       "      <td>MSR</td>\n",
       "      <td>10000</td>\n",
       "      <td>167.051580</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          分词工具  数据集   语句数量        运行时间\n",
       "0        jieba  MSR  10000    2.925063\n",
       "3       hannlp  MSR  10000   12.746340\n",
       "1       pkuseg  MSR  10000   14.527033\n",
       "2       thulac  MSR  10000   15.325316\n",
       "4      snownlp  MSR  10000  122.612315\n",
       "5  stanfordnlp  MSR  10000  167.051580"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "res = pd.read_csv('/Users/jiangchaodi/PycharmProjects/NLPRoadMap/evaluation/word_segment/result/time/0518-134135分词速度对比.csv')\n",
    "res.sort_values('运行时间')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从分词的速度上来看， jieba的速度是最快的。其次是hannlp和pkuseg。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 精度评测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们从三个维度来评价分词工具的精度：\n",
    "- 准确率： nlp工具正确分词数/nlp工具分词数\n",
    "- 召回率： nlp工具正确分词数/总正确正确分词数\n",
    "- F1分数： 2 *（准确率*召回率）/（准确率+找回率）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "进入evaluation/word_segment/目录， 在shell端运行以下代码(segment_file是人工切分数据集, raw为原始数据集)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "python evaluate.py eval_acc --segment_file=data/msr_segmented.txt --raw=data/msr_raw.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "运行成功后， 会在result/acc/下面的出现精度评测的csv文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "res_acc = pd.read_csv('/Users/jiangchaodi/PycharmProjects/NLPRoadMap/evaluation/word_segment/result/acc/0518-160315分词准确率对比.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_acc = res_acc.drop('NLP工具', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_acc.index=res['分词工具']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1分数</th>\n",
       "      <th>准确率</th>\n",
       "      <th>召回率</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>分词工具</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pkuseg</th>\n",
       "      <td>0.868859</td>\n",
       "      <td>0.861412</td>\n",
       "      <td>0.876436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thulac</th>\n",
       "      <td>0.849571</td>\n",
       "      <td>0.828052</td>\n",
       "      <td>0.872238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>snownlp</th>\n",
       "      <td>0.824881</td>\n",
       "      <td>0.802426</td>\n",
       "      <td>0.848630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hannlp</th>\n",
       "      <td>0.817140</td>\n",
       "      <td>0.824007</td>\n",
       "      <td>0.810387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jieba</th>\n",
       "      <td>0.807045</td>\n",
       "      <td>0.808098</td>\n",
       "      <td>0.805994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stanfordnlp</th>\n",
       "      <td>0.634253</td>\n",
       "      <td>0.596840</td>\n",
       "      <td>0.676670</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 F1分数       准确率       召回率\n",
       "分词工具                                     \n",
       "pkuseg       0.868859  0.861412  0.876436\n",
       "thulac       0.849571  0.828052  0.872238\n",
       "snownlp      0.824881  0.802426  0.848630\n",
       "hannlp       0.817140  0.824007  0.810387\n",
       "jieba        0.807045  0.808098  0.805994\n",
       "stanfordnlp  0.634253  0.596840  0.676670"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_acc.sort_values('F1分数', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到北大和清华的分词工具的F1分数是显著高于其他工具的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 自定义扩展"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 语料扩展"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在不同领域， 分词工具的分词效果是不同的， 所以本例中的评测效果尤其是精度只供参考。对特定领域的语料进行分词， 建议准备好相应的原始语料和切分好的语料， 像上面那样在运行时指定相应的文本位置参数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NLP工具扩展"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本文中我们只对6种主流分词工具进行了分词评测， 如果需要扩展， 只需要在**utility.py**中的SegTools类的方， 添加新的分词函数即可， 需要确保满足以下条件：  \n",
    "- 函数命名需以seg开头， 如seg_jieba\n",
    "- 部分函数需要加载模型， 建议将模型加载部分写在__init__中\n",
    "- 函数需要返回分词结果list， 比如['今天',  '天气', '真好']  \n",
    "如果只想对部分分词工具进行评测， 只需要注释掉相应的以seg开头的函数即可。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}